{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7703a241",
   "metadata": {},
   "source": [
    "## 1. **Definition**\n",
    "\n",
    "A **Decision Tree Classifier** is a supervised machine learning algorithm that recursively partitions data into subsets based on feature values, resulting in a tree-like model of decisions. Each internal node represents a decision rule on an attribute, each branch represents the outcome of the rule, and each leaf node represents a class label (the final prediction).\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **Splitting Criteria: Gini Impurity and Entropy**\n",
    "\n",
    "At each node, the decision tree chooses the feature and threshold that maximizes the \"purity\" of the resulting groups, i.e., makes them as homogeneous as possible regarding the target class.\n",
    "\n",
    "* **Gini Impurity:**\n",
    "  Measures the likelihood of incorrect classification of a randomly chosen element if it was randomly labeled according to the distribution of labels in the node.\n",
    "\n",
    "  $$\n",
    "  Gini = 1 - \\sum_{i=1}^{C} p_i^2\n",
    "  $$\n",
    "\n",
    "  where $p_i$ is the proportion of class $i$ samples in the node, and $C$ is the number of classes.\n",
    "\n",
    "* **Entropy:**\n",
    "  Measures the amount of disorder or uncertainty.\n",
    "\n",
    "  $$\n",
    "  Entropy = -\\sum_{i=1}^{C} p_i \\log_2 p_i\n",
    "  $$\n",
    "\n",
    "  A split that yields child nodes with lower Gini or Entropy is preferred.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. **Tree Depth**\n",
    "\n",
    "* **Tree Depth** is the maximum number of edges from the root node to a leaf node.\n",
    "* Deeper trees can capture more complex relationships but are more likely to overfit the training data.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. **Pruning**\n",
    "\n",
    "* **Pruning** is the process of reducing the size of the tree to avoid overfitting and improve generalization to unseen data.\n",
    "\n",
    "  * **Pre-pruning:** Limiting the growth of the tree (e.g., maximum depth, minimum samples per leaf).\n",
    "  * **Post-pruning:** Removing branches from a fully grown tree that do not provide significant power in predicting the target variable.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. **Formal Example**\n",
    "\n",
    "### **Dataset**\n",
    "\n",
    "Suppose we have a dataset of animals with two features: `Weight (kg)` and `Sound` (`Bark` or `Purr`). The goal is to classify whether the animal is a **Dog** or a **Cat**.\n",
    "\n",
    "| Weight (kg) | Sound | Class |\n",
    "| ----------- | ----- | ----- |\n",
    "| 8           | Bark  | Dog   |\n",
    "| 4           | Purr  | Cat   |\n",
    "| 5           | Purr  | Cat   |\n",
    "| 12          | Bark  | Dog   |\n",
    "| 6           | Purr  | Cat   |\n",
    "\n",
    "### **Tree Construction**\n",
    "\n",
    "**Step 1:**\n",
    "The tree algorithm evaluates possible splits—such as splitting on `Sound` or on `Weight`.\n",
    "\n",
    "Suppose it finds that splitting by `Sound` yields the purest groups:\n",
    "\n",
    "* If `Sound = Bark` → **Dog**\n",
    "* If `Sound = Purr` → **Cat**\n",
    "\n",
    "**Resulting Tree Structure:**\n",
    "\n",
    "```\n",
    "           [Sound?]\n",
    "          /        \\\n",
    "      Bark          Purr\n",
    "      /               \\\n",
    "    Dog              Cat\n",
    "```\n",
    "\n",
    "* **Gini impurity or Entropy for each leaf is 0** (all samples in each leaf are of a single class).\n",
    "\n",
    "\n",
    "## 6. **Summary Table**\n",
    "\n",
    "| Concept       | Formal Definition / Role                                         |\n",
    "| ------------- | ---------------------------------------------------------------- |\n",
    "| Decision Tree | Recursive partitioning, tree of decision nodes and leaves        |\n",
    "| Gini/Entropy  | Mathematical impurity metrics for selecting best splits          |\n",
    "| Tree Depth    | Maximum path length from root to leaf, controls model complexity |\n",
    "| Pruning       | Techniques to reduce tree size and prevent overfitting           |\n",
    "| Example       | Classifying Dog/Cat by Sound (Bark/Purr) and Weight              |\n",
    "\n",
    "---\n",
    "\n",
    "**In summary:**\n",
    "A Decision Tree classifier splits data using formal impurity measures (Gini or Entropy) to maximize class purity at each branch, with depth and pruning used to balance accuracy and generalization. The resulting model is a transparent series of decisions mapping features to class labels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418a137c",
   "metadata": {},
   "source": [
    "\n",
    "## **Step 1: The Dataset**\n",
    "\n",
    "| Index | Weight | Sound | Class |\n",
    "| ----- | ------ | ----- | ----- |\n",
    "| 1     | 8      | Bark  | Dog   |\n",
    "| 2     | 4      | Purr  | Cat   |\n",
    "| 3     | 5      | Purr  | Cat   |\n",
    "| 4     | 12     | Bark  | Dog   |\n",
    "| 5     | 6      | Purr  | Cat   |\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 2: Splitting by “Sound”**\n",
    "\n",
    "### **Split Groups:**\n",
    "\n",
    "* **Group 1 (Bark):** Index 1, 4\n",
    "\n",
    "  * Both are Dog\n",
    "* **Group 2 (Purr):** Index 2, 3, 5\n",
    "\n",
    "  * All are Cat\n",
    "\n",
    "### **Calculate Gini for Each Group**\n",
    "\n",
    "**Group 1 (Bark):**\n",
    "\n",
    "* 2 Dogs, 0 Cats\n",
    "* $p_\\text{Dog} = 1,\\ p_\\text{Cat} = 0$\n",
    "* $\\text{Gini}_{\\text{Bark}} = 1 - (1^2 + 0^2) = 0$\n",
    "\n",
    "**Group 2 (Purr):**\n",
    "\n",
    "* 3 Cats, 0 Dogs\n",
    "* $p_\\text{Cat} = 1,\\ p_\\text{Dog} = 0$\n",
    "* $\\text{Gini}_{\\text{Purr}} = 1 - (1^2 + 0^2) = 0$\n",
    "\n",
    "### **Calculate Weighted Gini for Split**\n",
    "\n",
    "* Group 1: 2/5, Group 2: 3/5\n",
    "\n",
    "$$\n",
    "\\text{Gini}_{\\text{split}} = \\frac{2}{5} \\times 0 + \\frac{3}{5} \\times 0 = 0\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 3: Splitting by “Weight”**\n",
    "\n",
    "We try all possible splits **between values**. The weights in order: 4, 5, 6, 8, 12. Possible split points:\n",
    "\n",
    "* Between 4 and 5 → 4.5\n",
    "* Between 5 and 6 → 5.5\n",
    "* Between 6 and 8 → 7\n",
    "* Between 8 and 12 → 10\n",
    "\n",
    "Let’s do the math for each:\n",
    "\n",
    "---\n",
    "\n",
    "### **A. Split at Weight < 4.5**\n",
    "\n",
    "* **Left:** Index 2 (weight 4) → Cat\n",
    "* **Right:** Index 1, 3, 4, 5 (weights 5, 6, 8, 12)\n",
    "\n",
    "**Left (1 Cat):**\n",
    "\n",
    "* $p_\\text{Cat} = 1,\\ p_\\text{Dog} = 0$\n",
    "* Gini = 0\n",
    "\n",
    "**Right (1 Dog, 2 Cats, 1 Dog):**\n",
    "\n",
    "* Index 1: Dog\n",
    "* Index 3: Cat\n",
    "* Index 4: Dog\n",
    "* Index 5: Cat\n",
    "* So, 2 Dogs, 2 Cats\n",
    "* $p_\\text{Dog} = 0.5,\\, p_\\text{Cat} = 0.5$\n",
    "* $\\text{Gini} = 1 - (0.5^2 + 0.5^2) = 1 - (0.25 + 0.25) = 0.5$\n",
    "\n",
    "**Weighted Gini:**\n",
    "\n",
    "* Left: 1/5 × 0 = 0\n",
    "* Right: 4/5 × 0.5 = 0.4\n",
    "* **Total:** 0.4\n",
    "\n",
    "---\n",
    "\n",
    "### **B. Split at Weight < 5.5**\n",
    "\n",
    "* **Left:** Index 2, 3 (weights 4, 5) → Cats\n",
    "* **Right:** Index 1, 4, 5 (weights 6, 8, 12)\n",
    "\n",
    "**Left (2 Cats):**\n",
    "\n",
    "* Gini = 0\n",
    "\n",
    "**Right:**\n",
    "\n",
    "* Index 1: Dog\n",
    "* Index 4: Dog\n",
    "* Index 5: Cat\n",
    "* 2 Dogs, 1 Cat\n",
    "* $p_\\text{Dog} = 2/3 \\approx 0.67,\\, p_\\text{Cat} = 1/3 \\approx 0.33$\n",
    "* $\\text{Gini} = 1 - (0.67^2 + 0.33^2) \\approx 1 - (0.4489 + 0.1089) = 1 - 0.5578 = 0.442$\n",
    "\n",
    "**Weighted Gini:**\n",
    "\n",
    "* Left: 2/5 × 0 = 0\n",
    "* Right: 3/5 × 0.442 ≈ 0.265\n",
    "* **Total:** ≈ 0.265\n",
    "\n",
    "---\n",
    "\n",
    "### **C. Split at Weight < 7**\n",
    "\n",
    "* **Left:** Index 2, 3, 5 (weights 4, 5, 6) → All Cats\n",
    "* **Right:** Index 1, 4 (weights 8, 12) → Both Dogs\n",
    "\n",
    "**Left (3 Cats):**\n",
    "\n",
    "* Gini = 0\n",
    "\n",
    "**Right (2 Dogs):**\n",
    "\n",
    "* Gini = 0\n",
    "\n",
    "**Weighted Gini:**\n",
    "\n",
    "* Left: 3/5 × 0 = 0\n",
    "* Right: 2/5 × 0 = 0\n",
    "* **Total:** 0\n",
    "\n",
    "---\n",
    "\n",
    "### **D. Split at Weight < 10**\n",
    "\n",
    "* **Left:** Index 1, 2, 3, 5 (weights 4, 5, 6, 8)\n",
    "* **Right:** Index 4 (weight 12)\n",
    "\n",
    "**Left:**\n",
    "\n",
    "* Index 1: Dog\n",
    "* Index 2: Cat\n",
    "* Index 3: Cat\n",
    "* Index 5: Cat\n",
    "* 1 Dog, 3 Cats\n",
    "* $p_\\text{Cat} = 3/4 = 0.75,\\, p_\\text{Dog} = 1/4 = 0.25$\n",
    "* $\\text{Gini} = 1 - (0.75^2 + 0.25^2) = 1 - (0.5625 + 0.0625) = 1 - 0.625 = 0.375$\n",
    "\n",
    "**Right:**\n",
    "\n",
    "* 1 Dog (Gini = 0)\n",
    "\n",
    "**Weighted Gini:**\n",
    "\n",
    "* Left: 4/5 × 0.375 = 0.3\n",
    "* Right: 1/5 × 0 = 0\n",
    "* **Total:** 0.3\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 4: Compare All Gini Values**\n",
    "\n",
    "| Split        | Weighted Gini |\n",
    "| ------------ | ------------- |\n",
    "| Sound        | 0             |\n",
    "| Weight < 4.5 | 0.4           |\n",
    "| Weight < 5.5 | 0.265         |\n",
    "| Weight < 7   | 0             |\n",
    "| Weight < 10  | 0.3           |\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 5: Which Split is Best?**\n",
    "\n",
    "* Both splitting by “Sound” and “Weight < 7” result in perfectly pure groups (Gini = 0).\n",
    "* Either split is mathematically perfect for this small dataset.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 6: What Would the Tree Look Like?**\n",
    "\n",
    "### **If Split by Sound:**\n",
    "\n",
    "```\n",
    "     Sound?\n",
    "    /      \\\n",
    " Bark     Purr\n",
    " Dog      Cat\n",
    "```\n",
    "\n",
    "### **If Split by Weight < 7:**\n",
    "\n",
    "```\n",
    "      Weight < 7?\n",
    "      /        \\\n",
    "   Yes         No\n",
    "  Cat         Dog\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Summary Table of Gini Values**\n",
    "\n",
    "| Feature | Split Point | Weighted Gini | Pure Leaves? |\n",
    "| ------- | ----------- | ------------- | ------------ |\n",
    "| Sound   | --          | 0             | Yes          |\n",
    "| Weight  | 4.5         | 0.4           | No           |\n",
    "| Weight  | 5.5         | 0.265         | No           |\n",
    "| Weight  | 7           | 0             | Yes          |\n",
    "| Weight  | 10          | 0.3           | No           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed22c6e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
