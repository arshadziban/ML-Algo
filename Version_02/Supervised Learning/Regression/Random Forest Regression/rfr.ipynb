{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cb4fff7",
   "metadata": {},
   "source": [
    "## What is Random Forest Regression?\n",
    "\n",
    "**Random Forest Regression** makes predictions by combining the results of several decision trees.  \n",
    "Each tree is trained on a random part of the data (a process called *bootstrapping*), and the final answer is the **average** of all tree predictions.\n",
    "\n",
    "## Example Dataset\n",
    "\n",
    "Suppose you have this data:\n",
    "\n",
    "| X | y |\n",
    "|---|---|\n",
    "| 1 | 3 |\n",
    "| 2 | 5 |\n",
    "| 3 | 7 |\n",
    "| 4 | 9 |\n",
    "\n",
    "## Building Two Simple Trees (Bootstrapping)\n",
    "\n",
    "Suppose you build **two simple trees** using random samples:\n",
    "\n",
    "- **Tree 1** is built from: (1,3), (2,5), (4,9), (2,5)  \n",
    "- **Tree 2** is built from: (2,5), (3,7), (4,9), (3,7)  \n",
    "\n",
    "## Predict for X = 3:\n",
    "\n",
    "### Tree 1's Prediction\n",
    "If X < 2.5: average(3,5,5) = 4.33  \n",
    "If X ≥ 2.5: predict 9\n",
    "\n",
    "For X = 3, **Tree 1 predicts 9**\n",
    "\n",
    "### Tree 2's Prediction\n",
    "If X < 3.5: average(5,7,7) = 6.33  \n",
    "If X ≥ 3.5: predict 9\n",
    "\n",
    "For X = 3, **Tree 2 predicts 6.33**\n",
    "\n",
    "## Final Random Forest Prediction\n",
    "\n",
    "Final prediction = (9 + 6.33)/2 = 7.67\n",
    "\n",
    "## Summary\n",
    "\n",
    "Random Forest combines multiple decision trees, each trained on different data samples. The final prediction is the average of all individual tree predictions, leading to more robust and accurate results than a single decision tree.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d029d533",
   "metadata": {},
   "source": [
    "# Random Forest Regression\n",
    "\n",
    "Random Forest Regression is an ensemble learning method that combines multiple decision trees to make accurate predictions.\n",
    "\n",
    "Key characteristics:\n",
    "- Uses bagging (bootstrap aggregating) to randomly sample data with replacement\n",
    "- Each tree is trained on a different subset of data\n",
    "- Trees are grown independently using different random subsets of features\n",
    "- Final prediction is the average of predictions from all trees\n",
    "\n",
    "Advantages:\n",
    "- More robust and accurate than single decision trees\n",
    "- Reduces overfitting through averaging\n",
    "- Can handle high-dimensional data\n",
    "- Provides feature importance rankings\n",
    "- Works well for both categorical and numerical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678f8d89",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
